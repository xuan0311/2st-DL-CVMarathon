{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day029-031閱讀重點\n",
    "## SSD object detection\n",
    "\n",
    "SSD演算法至今依舊是目標檢測中應用最廣泛的演算法，雖然後面有很多基於SSD改進的演算法，但至今也沒有哪一種檢測算法在速度和精度上能夠完全贏過SSD演算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入套件\n",
    "from ssd import build_ssd\n",
    "\n",
    "## box_utils裡面很多Function，可以看看是怎麼設計的\n",
    "from layers.box_utils import * \n",
    "from torch.autograd import Variable\n",
    "from layers import functions\n",
    "from layers import modules\n",
    "from math import sqrt \n",
    "from itertools import product\n",
    "from torch.autograd import Function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ssd.py 參數說明\n",
    "\n",
    "build_ssd('train', voc['min_dim'], voc['num_classes'])\n",
    "\n",
    "`\"train\"`:通常為\"train\"或者\"test\"字串。\n",
    "`voc['min_dim']`:圖片尺寸。\n",
    "`voc['num_classes']`:類別數量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Jupyter\\2st-DL-CVMarathon\\Day029-031\\Object Detection 程式導讀\\ssd.py:37: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "## 詳細模型結構可以參考ssd.py\n",
    "ssd_net=build_ssd('train', size=300, num_classes=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預設Config檔案在data/config.py內"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置檔案定義域config.py，專門用來預先設定相關配置的參數設定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_classes': 21,\n",
       " 'lr_steps': (80000, 100000, 120000),\n",
       " 'max_iter': 120000,\n",
       " 'feature_maps': [38, 19, 10, 5, 3, 1],\n",
       " 'min_dim': 300,\n",
       " 'steps': [8, 16, 32, 64, 100, 300],\n",
       " 'min_sizes': [30, 60, 111, 162, 213, 264],\n",
       " 'max_sizes': [60, 111, 162, 213, 264, 315],\n",
       " 'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
       " 'variance': [0.1, 0.2],\n",
       " 'clip': True,\n",
       " 'name': 'VOC'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd_net.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'num_classes': 21,\n",
    "    'lr_steps': (80000, 100000, 120000),\n",
    "    'max_iter': 120000,\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],\n",
    "    'min_dim': 300,\n",
    "    'steps': [8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "    'variance': [0.1, 0.2],\n",
    "    'clip': True,\n",
    "    'name': 'VOC',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'aspect_ratios'` : 使用六張Feature Map，每一張上方有預設的anchor boxes，Boxes aspect ratio可以自己設定\n",
    "### `'feature_maps' `: 使用feature map大小為[38x38, 19x19, 10x10, 5x5, 3x3, 1x1]\n",
    "### `'min_sizes'`、`'max_sizes'`可藉由下方算式算出，由作者自行設計\n",
    "### '`steps'` : Feature map回放回原本300*300的比例，如38要回放為300大概就是8倍\n",
    "### `'variance'`: Training 的一個特技(trick)，加速收斂，詳見：https://github.com/rykov8/ssd_keras/issues/53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ` 'min_sizes'`、`'max_sizes'` 計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "六個特徵層共產生6組`min_sizes`和`max_sizes`。另外`min_dim`=300，ratio取20到90即`min_ratio`=20，`max_ratio`=90。\n",
    "\n",
    "根據下面程式碼的計算公式，我們還需要`step`，注意是`step`不是`steps`，兩者的作用不一樣。這裡計算後\n",
    "\n",
    "`step`=（max_ratio-min_ratio）/(len(mbox_source_layers)-2) = (90-20)/(6-2)=17，\n",
    "\n",
    "要說這個`step`的作用，其實就是取一個間隔。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_sizes:  [30.0, 60.0, 111.0, 162.0, 213.0, 264.0]\n",
      "max_sizes:  [60.0, 111.0, 162.0, 213.0, 264.0, 315.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "## source:https://blog.csdn.net/gbyy42299/article/details/81235891\n",
    "min_dim = 300   ## 維度\n",
    "# conv4_3 ==> 38 x 38\n",
    "# fc7 ==> 19 x 19\n",
    "# conv6_2 ==> 10 x 10\n",
    "# conv7_2 ==> 5 x 5\n",
    "# conv8_2 ==> 3 x 3\n",
    "# conv9_2 ==> 1 x 1\n",
    "mbox_source_layers = ['conv4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'conv9_2'] ## prior_box來源層，可以更改。很多改進都是基於此處的調整。\n",
    "# in percent %\n",
    "min_ratio = 20 ## 這裡即是論文中所說的Smin的= 0.2，Smax的= 0.9的初始值，經過下面的運算即可得到min_sizes，max_sizes。\n",
    "max_ratio = 90\n",
    "step = int(math.floor((max_ratio - min_ratio) / (len(mbox_source_layers) - 2)))## 取一個間距步長，即在下面用於循環給比取值時起一個間距作用。可以用一個具體的數值代替，這裡等於17。\n",
    "## 經過以下運算得到min_sizes和max_sizes。\n",
    "min_sizes = [] #定義數組min_sizes[]，用來存放計算結果。\n",
    "max_sizes = [] #定義數組max_sizes[]，用來存放計算結果。\n",
    "for ratio in range(min_ratio, max_ratio + 1, step):\n",
    "    ## 從min_ratio至max_ratio + 1每隔步驟= 17取一個值賦值給比。注意範圍函數的作用。\n",
    "    ## min_sizes.append（）函數即把括號內部每次得到的值依次給了min_sizes。\n",
    "    min_sizes.append(min_dim * ratio / 100.)\n",
    "    max_sizes.append(min_dim * (ratio + step) / 100.)\n",
    "min_sizes = [min_dim * 10 / 100.] + min_sizes\n",
    "max_sizes = [min_dim * 20 / 100.] + max_sizes\n",
    "\"\"\"\n",
    "得到結果為 min_sizes=[300*10/100]+0=30，max_sizes= [300*20/100]+0=60。\n",
    "\"\"\"\n",
    "\n",
    "## steps: 這一步要仔細理解，即計算卷積層產生的prior_box距離原圖的步長，先驗框中心點的坐標會乘以step，\n",
    "## 相當於從特徵映射位置映射回原圖位置，比如conv4_3輸出特徵圖大小為38 *38，而輸入的圖片為300* 300，\n",
    "## 所以38*8約等於300，所以映射步長為8.這是針對300* 300的訓練圖片。\n",
    "steps = [8, 16, 32, 64, 100, 300]  \n",
    "aspect_ratios = [[2], [2, 3], [2, 3], [2, 3], [2], [2]]\n",
    " \n",
    "print('min_sizes: ',min_sizes)\n",
    "print('max_sizes: ',max_sizes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據程式碼\n",
    "`for ratio in xrange(min_ratio, max_ratio+1, step):`（這句的意思即在`min_ratio`與`max_ratio`之間即20-90之間以step=17為間隔產生一組數據賦值給ratio），最終`ratio`=[20，37，54，71，88]。所以對於剩餘5層所產生的min_sizes和max_sizes分別為：\n",
    "\n",
    "`fc7`：min_sizes=min_dim x ratio/100 = 300*20/100=60，max_sizes=min_dim x (ratio+step)/100=300*(20+17)/100=111；\n",
    "\n",
    "`conv6_2`：min_sizes=min_dim x ratio/100 = 300*37/100=111，max_sizes=min_dim x (ratio+step)/100 = 300*(37+17)/100=162；\n",
    "\n",
    "`conv7_2`：min_sizes=min_dim x ratio/100 = 300*54/100=162，max_sizes=min_dim x (ratio+step)/100 = 300*(54+17)/100=213；\n",
    "\n",
    "`conv8_2`：min_sizes=min_dim x ratio/100 =300*71/100=213，max_sizes=min_dim x (ratio+step)/100 = 300*(71+17)/100=264；\n",
    "\n",
    "`conv9_2`：min_sizes=min_dim x ratio/100 = 300*88/100=213，max_sizes=min_dim x (ratio+step)/100 = 300*(88+17)/100=315；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default anchor boxes設計原理，看懂收穫很多\n",
    "##### 可以理解 SSD原文中 8732個anchors是怎麼來的\n",
    "##### 38×38×4+19×19×6+10×10×6+5×5×6+3×3×4+1×1×4=8732"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward()`函數的中`mean`變量保存了一張圖片中各個先驗框的中心坐標和長寬(均是相對值)，先驗框主要是計算損失函數的時候用到，前向傳播的時候，直接對每張圖片複製`mean`張量即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class用來定義類別，名稱為:PriorBox\n",
    "class PriorBox(object):\n",
    "    \"\"\"Compute priorbox coordinates in center-offset form for each source\n",
    "    feature map.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    __init__這個特定的名稱，用來定義類別的實例建立之後，要進行的初始化動作。\n",
    "    第一個self參數代表建立的類別實例，在Python中，實例可操作的方法，第一個參數必須明確作為接受實例之用，\n",
    "    慣例上取名為self名稱，__init__之後則可指定初始化時所必須給定的資料。\n",
    "    \"\"\"\n",
    "    # cfg是定義在data/config.py裡面，是模型的相關配置\n",
    "    def __init__(self, cfg):\n",
    "        super(PriorBox, self).__init__()\n",
    "        self.image_size = cfg['min_dim'] #輸入數據分辨率，一般為300\n",
    "        # number of priors for feature map location (either 4 or 6)\n",
    "        self.num_priors = len(cfg['aspect_ratios']) #輸出特徵圖的數量\n",
    "        self.variance = cfg['variance'] or [0.1] #尺度\n",
    "        self.feature_maps = cfg['feature_maps'] #各個輸出特徵圖的分辨率\n",
    "        #計算檢驗框用到的Smin和Smax\n",
    "        self.min_sizes = cfg['min_sizes']\n",
    "        self.max_sizes = cfg['max_sizes']\n",
    "        #各個輸出特徵圖每個像素對應到原圖的大小\n",
    "        self.steps = cfg['steps']\n",
    "        #輸出特徵圖用到的比例\n",
    "        self.aspect_ratios = cfg['aspect_ratios']\n",
    "        self.clip = cfg['clip']\n",
    "        self.version = cfg['name']\n",
    "        for v in self.variance:\n",
    "            if v <= 0:\n",
    "                raise ValueError('Variances must be greater than 0')\n",
    "\n",
    "    def forward(self):\n",
    "        mean = []\n",
    "        '''依照Feature map大小找出所有的pixel 中心'''\n",
    "        '''下方這兩個loop會找出W個x軸pixel對上W個y軸pixel，假如現在是在38x38的feature map上，就會有38x38個值'''\n",
    "        '''ex. [0,1],[0,2]..[0,37] [1,1],[1,2]..[1,37]..........[37,37]'''\n",
    "        for k, f in enumerate(self.feature_maps): #f是特徵圖的邊長\n",
    "            for i, j in product(range(f), repeat=2):\n",
    "                # steps是输出特徵圖輸出的下採樣率，f_k是特徵圖的邊長\n",
    "                f_k = self.image_size / self.steps[k] ## 如self.steps==8，就是先將原圖size normalize(/300)後再乘上8\n",
    "                # unit center x,y\n",
    "                '''檢驗框的中心點計算公式'''\n",
    "                cx = (j + 0.5) / f_k #每一個檢驗框的x座標cx\n",
    "                cy = (i + 0.5) / f_k #每一個檢驗框的y座標cy\n",
    "\n",
    "                # aspect_ratio: 1\n",
    "                # rel size: min_size\n",
    "                '''/self.image_size 就是在做normalization '''\n",
    "                s_k = self.min_sizes[k]/self.image_size\n",
    "                '''小的正方形box'''\n",
    "                mean += [cx, cy, s_k, s_k]\n",
    "                \"\"\"\n",
    "                每个特徵圖使用的檢驗框大小：\n",
    "                Sk=Smin+(Smax-Smin)(k-1)/(m-1)，k的值[1,m]，m是輸出特徵圖的數量，\n",
    "                Sk是檢驗框相對於整张圖片的比例，Smin=0.2，Smax=0.95\n",
    "                檢驗框的寬度:w_k_a=Sk*ar^0.5，檢驗框的高度:h_k_a=Sk/ar^0.5，\n",
    "                其中ar是特徵圖的比例，有[3, 2, 1, 1/2, 1/3]\n",
    "                \"\"\"\n",
    "\n",
    "                #下面计算各個比例的檢驗框的寬與高，並把他們放到list()裡面\n",
    "                #注意這裡的寬、高是相對於原圖的比例\n",
    "                # aspect_ratio: 1\n",
    "                # rel size: sqrt(s_k * s_(k+1))\n",
    "                '''大的正方形box'''\n",
    "                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))\n",
    "                mean += [cx, cy, s_k_prime, s_k_prime]\n",
    "\n",
    "                # rest of aspect ratios\n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    '''aspect ratio 2,3'''\n",
    "                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]\n",
    "                    '''aspect ratio 1/2,1/3'''\n",
    "                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]\n",
    "        # back to torch land，reshape檢驗框\n",
    "        output = torch.Tensor(mean).view(-1, 4)\n",
    "        #clamp_將output張量每個元素的夾緊到[min,max]區間，並返回結果到一個新張量，其實就是常用的截斷函數（分段閾值）。\n",
    "        if self.clip:\n",
    "            output.clamp_(max=1, min=0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriorBox_Demo=PriorBox(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8732, 4])\n"
     ]
    }
   ],
   "source": [
    "print(PriorBox_Demo.forward().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss 如何設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class用來定義類別，名稱為:MultiBoxLoss\n",
    "class MultiBoxLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__這個特定的名稱，用來定義類別的實例建立之後，要進行的初始化動作。\n",
    "    第一個self參數代表建立的類別實例，在Python中，實例可操作的方法，第一個參數必須明確作為接受實例之用，\n",
    "    慣例上取名為self名稱，__init__之後則可指定初始化時所必須給定的資料。\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, overlap_thresh, prior_for_matching,\n",
    "                 bkg_label, neg_mining, neg_pos, neg_overlap, encode_target,\n",
    "                 use_gpu=True):\n",
    "        super(MultiBoxLoss, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "        '''有幾類'''\n",
    "        self.num_classes = num_classes\n",
    "        '''判定為正樣本的threshold，一般設為0.5'''\n",
    "        self.threshold = overlap_thresh\n",
    "        '''background自己會有一類，不用Label，假如我們有20類一樣標註0-19，下方會自己空出一類給background'''\n",
    "        self.background_label = bkg_label\n",
    "        self.encode_target = encode_target\n",
    "        self.use_prior_for_matching = prior_for_matching\n",
    "        '''OHEM，找出分得最不好的樣品，也就是confidence score比較低的正負樣品'''\n",
    "        self.do_neg_mining = neg_mining\n",
    "        '''負樣品與正樣品的比例，通常是3:1'''\n",
    "        self.negpos_ratio = neg_pos\n",
    "        self.neg_overlap = neg_overlap\n",
    "        self.variance = cfg['variance']\n",
    "     \n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "\n",
    "        '''prediction會output三個值'''\n",
    "        '''loc shape: bounding box 資訊，torch.size(batch_size,num_priors,4)'''\n",
    "        '''conf shape: 每一個bounding box 的信心程度，torch.size(batch_size,num_priors,num_classes)'''\n",
    "        '''priors shape: 預設的defaul box， torch.size(num_priors,4)'''\n",
    "        loc_data, conf_data, priors = predictions\n",
    "        num = loc_data.size(0) # batchsize\n",
    "        priors = priors[:loc_data.size(1), :]\n",
    "        num_priors = (priors.size(0))\n",
    "        num_classes = self.num_classes\n",
    "\n",
    "        # match priors (default boxes) and ground truth boxes\n",
    "        loc_t = torch.Tensor(num, num_priors, 4)\n",
    "        conf_t = torch.LongTensor(num, num_priors)\n",
    "        for idx in range(num):\n",
    "            truths = targets[idx][:, :-1].data # ground truth box信息\n",
    "            labels = targets[idx][:, -1].data # ground truth conf信息\n",
    "            defaults = priors.data\n",
    "            '''jaccard 計算每一個BBOX與ground truth的IOU'''\n",
    "            # 匹配 ground truth\n",
    "            match(self.threshold, truths, defaults, self.variance, labels,\n",
    "                  loc_t, conf_t, idx)\n",
    "        # use gpu\n",
    "        if self.use_gpu:\n",
    "            loc_t = loc_t.cuda()\n",
    "            conf_t = conf_t.cuda()\n",
    "        '''用Variable包裝'''\n",
    "        loc_t = Variable(loc_t, requires_grad=False)\n",
    "        conf_t = Variable(conf_t, requires_grad=False)\n",
    "\n",
    "        pos = conf_t > 0 # 匹配中所有的正樣本 mask,shape[b,M]\n",
    "        num_pos = pos.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # Localization Loss,使用 Smooth L1\n",
    "        # shape[b,M]-->shape[b,M,4]\n",
    "        pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)\n",
    "        loc_p = loc_data[pos_idx].view(-1, 4) # 預測的正樣本box訊息\n",
    "        loc_t = loc_t[pos_idx].view(-1, 4) # 真實的正樣本box信息\n",
    "        '''smooth_l1_loss 計算bounding box regression'''\n",
    "        loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False) # Smooth L1 損失\n",
    "\n",
    "        # Compute max conf across batch for hard negative mining\n",
    "        # shape[b*M,num_classes]\n",
    "        batch_conf = conf_data.view(-1, self.num_classes)\n",
    "        # 使用logsoftmax，計算置信度,shape[b*M, 1]\n",
    "        loss_c = log_sum_exp(batch_conf) - batch_conf.gather(1, conf_t.view(-1, 1))\n",
    "\n",
    "        # Hard Negative Mining\n",
    "        loss_c = loss_c.view(num, -1) # shape[b, M]\n",
    "        loss_c[pos] = 0 # 把正樣本排除，剩下的就全是負樣本，可以進行抽樣\n",
    "        '''排列confidence 的分數'''\n",
    "        # 兩次sort排序，能夠得到每個元素在降序排列中的位置idx_rank\n",
    "        _, loss_idx = loss_c.sort(1, descending=True)\n",
    "        _, idx_rank = loss_idx.sort(1)\n",
    "        \n",
    "        # 抽取負樣本\n",
    "        # 每個atch中正樣本的数目，shape[b,1]\n",
    "        num_pos = pos.long().sum(1, keepdim=True)\n",
    "        '''負樣品取出數量 == negpos_ratio*num_pos'''\n",
    "        num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(1)-1)\n",
    "        neg = idx_rank < num_neg.expand_as(idx_rank) # 抽取前 top_k 個負样本，shape[b, M]\n",
    "\n",
    "        # Confidence Loss Including Positive and Negative Examples\n",
    "        # shape[b,M] --> shape[b,M,num_classes]\n",
    "        pos_idx = pos.unsqueeze(2).expand_as(conf_data)\n",
    "        neg_idx = neg.unsqueeze(2).expand_as(conf_data)\n",
    "        # 提取出所有篩選好的正負樣本(預測的與真實的)\n",
    "        conf_p = conf_data[(pos_idx+neg_idx).gt(0)].view(-1, self.num_classes)\n",
    "        targets_weighted = conf_t[(pos+neg).gt(0)]\n",
    "        '''用cross_entropy做分類'''\n",
    "        # 計算cross_entropy\n",
    "        loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False)\n",
    "\n",
    "        # Sum of losses: L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N\n",
    "        # double轉成torch.float64\n",
    "        # 正樣本個數\n",
    "        N = num_pos.data.sum().double()\n",
    "        loss_l = loss_l.double()\n",
    "        loss_c = loss_c.double()\n",
    "        loss_l /= N\n",
    "        loss_c /= N\n",
    "        return loss_l, loss_c #loss_l:定位損失與loss_c分類損失\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 產生我們Loss function，注意這裡的class要包含背景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_class:類別數量21\\noverlap_thresh:0.5\\nprior_for_matching = TRUE\\nbkg_label = 0 \\nneg_mining = False\\nneg_pos = 3\\nneg_overlap = 0.5\\nencode_target = False\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Use_cuda=False\n",
    "criterion = MultiBoxLoss(21, 0.5, True, 0, False, 3, 0.5,False, Use_cuda,)\n",
    "\"\"\"\n",
    "num_class:類別數量21\n",
    "overlap_thresh:0.5\n",
    "prior_for_matching = TRUE\n",
    "bkg_label = 0 \n",
    "neg_mining = False\n",
    "neg_pos = 3\n",
    "neg_overlap = 0.5\n",
    "encode_target = False\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_net=build_ssd('train', size=300, num_classes=21)\n",
    "use_pretrained=False\n",
    "if use_pretrained:\n",
    "    ssd_net.load_weights('./demo/ssd300_mAP_77.43_v2.pth')\n",
    "net=ssd_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: It looks like you have a CUDA device, but aren't using CUDA.\n",
      "Run with --cuda for optimal training speed.\n"
     ]
    }
   ],
   "source": [
    "'''要不要使用gpu'''\n",
    "Use_cuda=False\n",
    "\n",
    "'''tensor type會依照cpu或gpu有所不同'''\n",
    "if torch.cuda.is_available():\n",
    "    if Use_cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    else:\n",
    "        print(\"WARNING: It looks like you have a CUDA device, but aren't \" +\n",
    "              \"using CUDA.\\nRun with --cuda for optimal training speed.\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "\n",
    "'''使用GPU時模型要轉成cuda'''\n",
    "if Use_cuda:\n",
    "    net = net.cuda()\n",
    "    \n",
    "batch_size_=32\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.00001/batch_size_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 這裡我們先示範輸入的 image,Label格式，真正在訓練時，準備成一樣格式即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "'''輸入影像格式，假設batch size 為 4'''\n",
    "image_in=torch.tensor(torch.rand(4,3,300,300),dtype=torch.float32)\n",
    "'''Label格式，沒有固定長度，看圖像中有幾個label就有幾個'''\n",
    "label_0=[[ 0.1804,  0.6076,  0.7701,  0.8485, 0.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 3.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 19.0000],\n",
    "       [ 0.2950,  0.0000,  0.8238,  0.3641, 6.0000],]\n",
    "label_1=[[ 0.1804,  0.6076,  0.7701,  0.8485, 13.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 11.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 7.0000],\n",
    "       [ 0.2950,  0.0000,  0.8238,  0.3641, 5.0000],]\n",
    "label_2=[[ 0.1804,  0.6076,  0.7701,  0.8485, 0.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 3.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 14.0000],\n",
    "       [ 0.2950,  0.0000,  0.8238,  0.3641, 6.0000],]\n",
    "label_3=[[ 0.1804,  0.6076,  0.7701,  0.8485, 0.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 3.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 19.0000],\n",
    "       [ 0.2950,  0.0000,  0.8238,  0.3641, 6.0000],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=300\n",
    "iteration=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBOX Regression Loss:  2.5155847902651187\n",
      "Classification Loss:  14.467122395833334\n",
      "BBOX Regression Loss:  2.51545251916956\n",
      "Classification Loss:  14.362959402578847\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    n=0\n",
    "    loss_sum=[]\n",
    "    loc_loss=[]\n",
    "    conf_loss=[]\n",
    "    for number__ in range(iteration) :\n",
    "        '''要用Variable包裝tensor才能送入模型'''\n",
    "        if Use_cuda:\n",
    "            image_ = Variable(image_in.cuda())\n",
    "            y = [Variable(torch.tensor(label_0).cuda(), volatile=True),Variable(torch.tensor(label_1).cuda(), \n",
    "                volatile=True),Variable(torch.tensor(label_2).cuda(), volatile=True),Variable(torch.tensor(label_3).cuda(), volatile=True)]      \n",
    "        else:\n",
    "            image_ = Variable(image_in)\n",
    "            y = [Variable(torch.tensor(label_0), volatile=True),Variable(torch.tensor(label_1), \n",
    "                volatile=True),Variable(torch.tensor(label_2), volatile=True),Variable(torch.tensor(label_3), volatile=True)]\n",
    "\n",
    "        '''Forward Pass'''\n",
    "        out = net(image_)\n",
    "        '''Regression Loss and Classification Loss'''\n",
    "        loss_l,loss_c = criterion(out,y )\n",
    "        loss = loss_l+ loss_c\n",
    "        '''Backward'''\n",
    "        loss.backward()\n",
    "\n",
    "        loc_loss.append(loss_l.data.cpu().numpy())\n",
    "        conf_loss.append(loss_c.data.cpu().numpy())\n",
    "        loss_sum.append(loss.data.cpu().numpy())\n",
    "        '''更新參數'''\n",
    "        optimizer.step()\n",
    "        '''清空Gradients'''\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        n+=1\n",
    "        if n%10==0:\n",
    "            print('BBOX Regression Loss: ', np.mean(loc_loss))\n",
    "            print('Classification Loss: ', np.mean(conf_loss))\n",
    "    '''儲存權重'''\n",
    "    torch.save(ssd_net.state_dict(),'weights/Weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 想要Train VOC,COCO可以參考原Github:https://github.com/amdegroot/ssd.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
