{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 學習如何搭建Inception Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 了解Inceotion原理\n",
    "  #### 了解如何導入Inception block到原本架構中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Incpeiton](Inception架構.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# 載入套件\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 導入InceptionV2-有BatchNormalization的Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d_bn(x,filters,kernel_size,padding='same',strides=(1, 1),normalizer=True,activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        conv_name = name + '_conv'\n",
    "        bn_name = name + '_bn'\n",
    "        act_name = name + '_act'\n",
    "    else:\n",
    "        conv_name = None\n",
    "        bn_name = None\n",
    "        act_name = None\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Conv2D(\n",
    "            filters, kernel_size,\n",
    "            strides=strides, padding=padding,\n",
    "            use_bias=False, name=conv_name)(x)\n",
    "    if normalizer:\n",
    "        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    if activation:\n",
    "        x = Activation(activation, name=act_name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考上圖搭建 InceptionV1_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionV1_block(x, specs,channel_axis, name):\n",
    "    (br0, br1, br2, br3) = specs   # ((64,), (96,128), (16,32), (32,))\n",
    "    '''\n",
    "    x: 輸入圖形的shape\n",
    "    brx[0]:過濾器數量\n",
    "    (x,x):kernel_size\n",
    "    name: 該層命名\n",
    "    '''\n",
    "    branch_0 = Conv2d_bn(x, br0[0], (1, 1), name = name +\"_Branch_0\")\n",
    "\n",
    "    branch_1 = Conv2d_bn(x, br1[0], (1, 1), name = name+\"_Branch_1\")\n",
    "    branch_1 = Conv2d_bn(branch_1, br1[1], (3, 3), name = name+\"_Branch_1_1\")\n",
    "\n",
    "    '''Branch_2'''\n",
    "    branch_2 = Conv2d_bn(x, br2[0], (1, 1), name = name+\"_Branch_2\")\n",
    "    branch_2 = Conv2d_bn(branch_2, br2[1], (5, 5), name = name+\"_Branch_2_1\")\n",
    "\n",
    "    '''Branch_3'''\n",
    "    branch_3 = MaxPooling2D((3, 3), strides=(1, 1),padding = 'same', name = name+\"_Branch_3\")(x)\n",
    "    branch_3 = Conv2d_bn(branch_3, br3[0], (1, 1), name = name+\"_Branch_3_1\")\n",
    "    \n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name=name+\"_Concatenated\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Tensor(\"Block_1_Concatenated/concat:0\", shape=(?, 224, 224, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(224,224,1))\n",
    "x=InceptionV1_block(img_input, ((64,), (96,128), (16,32), (32,)), 3, 'Block_1')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將 InceptionV1_block中n*n卷積改為1 x n+n x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionV3_block(x, specs,channel_axis, name):\n",
    "    (br0, br1, br2, br3) = specs   # ((64,), (96,128), (16,32), (32,))\n",
    "    '''\n",
    "    x: 輸入圖形的shape\n",
    "    brx[0]:過濾器數量\n",
    "    (x,x):kernel_size\n",
    "    name: 該層命名\n",
    "    '''\n",
    "    branch_0 = Conv2d_bn(x, br0[0], (1, 1), name=name+\"_Branch_0\")\n",
    "\n",
    "    branch_1 = Conv2d_bn(x, br1[0], (1, 1), name=name+\"_Branch_1\")\n",
    "    branch_1 = Conv2d_bn(branch_1, br1[1], (1, 3), name=name+\"_Branch_1_1\")\n",
    "    branch_1 = Conv2d_bn(branch_1, br1[1], (3, 1), name=name+\"_Branch_1_2\")\n",
    "\n",
    "    '''Branch_2'''\n",
    "    branch_2 = Conv2d_bn(x, br1[0], (1, 1), name=name+\"_Branch_2\")\n",
    "    branch_2 = Conv2d_bn(branch_1, br1[1], (1, 5), name=name+\"_Branch_2_1\")\n",
    "    branch_2 = Conv2d_bn(branch_1, br1[1], (5, 1), name=name+\"_Branch_2_2\")\n",
    "\n",
    "    '''Branch_3'''\n",
    "    branch_3 = MaxPooling2D((3, 3), strides=(1, 1),padding='same', name=name+'_pool')(x)\n",
    "    branch_3 = Conv2d_bn(branch_3, br3[0], (1, 1), name=name+\"_Branch_3\")\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name=name+\"_Concatenated\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Block_1_Concatenated_1/concat:0\", shape=(?, 224, 224, 352), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(224,224,1))\n",
    "x=InceptionV3_block(img_input, ((64,), (96,128), (16,32), (32,)), 3, 'Block_1')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 額外練習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將VGG16 Block_3中的Convolution全部改為InceptionV1_block\n",
    "## Block_5中的Convolution全部改為InceptionV3_block\n",
    "## 並將所有Convolution改為Conv2d_bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 原vgg16架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, #include_top：是否包含頂部(Top) 3層『完全連階層』(fully-connected layers)。\n",
    "          input_tensor=None, \n",
    "          input_shape=(224,224,1),\n",
    "          pooling='max',\n",
    "          classes=1000):\n",
    " \n",
    "    img_input = Input(shape=input_shape)\n",
    "    #過濾器=64, kernel_size=(3,3),激活函數='relu',填充='same',輸入大小=(224,224,1)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    #過濾器=64, kernel_size=(3,3),激活函數='relu,填充='same',輸入大小=input_shape\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    #pooling_size=2,2 strides=2,2 \n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    #過濾器=128, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    #過濾器=128, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    #pooling_size=2,2 strides=2,2 \n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    '''可參考上面的搭法'''\n",
    "    #過濾器=256, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "     #過濾器=256, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    #過濾器=256, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    #pooling_size=2,2 strides=2,2 \n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    # Block 4\n",
    "    '''可參考上面的搭法'''\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    #pooling_size=2,2 strides=2,2 \n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    # Block 5\n",
    "    '''可參考上面的搭法'''\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    #pooling_size=2,2 strides=2,2\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)#全連接層輸出向量長度等於神經元的數量\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x) #使用4096個神經元\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "   \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 修改後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_Inception(include_top=True, #include_top：是否包含頂部(Top) 3層『完全連階層』(fully-connected layers)。\n",
    "                    input_tensor=None, \n",
    "                    input_shape=(224,224,1),\n",
    "                    pooling='max',\n",
    "                    classes=1000):\n",
    " \n",
    "    img_input = Input(shape=input_shape)\n",
    "    '''修改模型'''\n",
    "    #Block1\n",
    "    #過濾器=64, kernel_size=(3,3),激活函數='relu',輸入大小=(224,224,1)\n",
    "    x = Conv2d_bn(img_input,64, (3, 3), activation='relu',padding='same', name='block1_conv1')\n",
    "    #過濾器=64, kernel_size=(3,3),激活函數='relu,輸入大小=input_shape\n",
    "    x = Conv2d_bn(x,64, (3, 3), activation='relu',padding='same', name='block1_conv2')\n",
    "    #pooling_size=2,2 strides=2,2 \n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    #過濾器=128, kernel_size=(3,3),激活函數='relu'\n",
    "    x = Conv2d_bn(x,128, (3, 3), activation='relu',padding='same', name='block2_conv1')\n",
    "    #過濾器=128, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2d_bn(x,128, (3, 3), activation='relu',padding='same', name='block2_conv2')\n",
    "    #pooling_size=(2,2)、 strides=(2,2) \n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    #過濾器=256, kernel_size=(3,3),激活函數='relu'\n",
    "    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'block3_conv1')\n",
    "    #過濾器=256, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'block3_conv2')\n",
    "    #過濾器=256, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'block3_conv3')\n",
    "    #pooling_size=(2,2) strides=(2,2)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu'\n",
    "    x = Conv2d_bn(x,512, (3, 3), activation='relu',padding='same', name='block4_conv1')\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2d_bn(x,512, (3, 3), activation='relu',padding='same', name='block4_conv2')\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu',填充='same'\n",
    "    x = Conv2d_bn(x,512, (3, 3), activation='relu',padding='same', name='block4_conv3')\n",
    "    #pooling_size=(2,2) strides=(2,2) \n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu'\n",
    "    x = InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'block5_conv1')\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu'\n",
    "    x = InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'block5_conv2')\n",
    "    #過濾器=512, kernel_size=(3,3),激活函數='relu'\n",
    "    x = InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'block5_conv3')\n",
    "    #pooling_size=(2,2) strides=(2,2)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16_modify')\n",
    "   \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16_Inception(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_conv (Conv2D)      (None, 224, 224, 64) 576         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 224, 224, 64) 192         block1_conv1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 224, 224, 64) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_conv (Conv2D)      (None, 224, 224, 64) 36864       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 224, 224, 64) 192         block1_conv2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 224, 224, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_conv (Conv2D)      (None, 112, 112, 128 73728       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_bn (BatchNormaliza (None, 112, 112, 128 384         block2_conv1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_act (Activation)   (None, 112, 112, 128 0           block2_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_conv (Conv2D)      (None, 112, 112, 128 147456      block2_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_bn (BatchNormaliza (None, 112, 112, 128 384         block2_conv2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_act (Activation)   (None, 112, 112, 128 0           block2_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_1_conv (Con (None, 56, 56, 96)   12288       block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_2_conv (Con (None, 56, 56, 16)   2048        block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_1_bn (Batch (None, 56, 56, 96)   288         block3_conv1_Branch_1_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_2_bn (Batch (None, 56, 56, 16)   48          block3_conv1_Branch_2_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_1_act (Acti (None, 56, 56, 96)   0           block3_conv1_Branch_1_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_2_act (Acti (None, 56, 56, 16)   0           block3_conv1_Branch_2_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_3 (MaxPooli (None, 56, 56, 128)  0           block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_0_conv (Con (None, 56, 56, 64)   8192        block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_1_1_conv (C (None, 56, 56, 128)  110592      block3_conv1_Branch_1_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_2_1_conv (C (None, 56, 56, 32)   12800       block3_conv1_Branch_2_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_3_1_conv (C (None, 56, 56, 32)   4096        block3_conv1_Branch_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_0_bn (Batch (None, 56, 56, 64)   192         block3_conv1_Branch_0_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_1_1_bn (Bat (None, 56, 56, 128)  384         block3_conv1_Branch_1_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_2_1_bn (Bat (None, 56, 56, 32)   96          block3_conv1_Branch_2_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_3_1_bn (Bat (None, 56, 56, 32)   96          block3_conv1_Branch_3_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_0_act (Acti (None, 56, 56, 64)   0           block3_conv1_Branch_0_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_1_1_act (Ac (None, 56, 56, 128)  0           block3_conv1_Branch_1_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_2_1_act (Ac (None, 56, 56, 32)   0           block3_conv1_Branch_2_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Branch_3_1_act (Ac (None, 56, 56, 32)   0           block3_conv1_Branch_3_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_Concatenated (Conc (None, 56, 56, 256)  0           block3_conv1_Branch_0_act[0][0]  \n",
      "                                                                 block3_conv1_Branch_1_1_act[0][0]\n",
      "                                                                 block3_conv1_Branch_2_1_act[0][0]\n",
      "                                                                 block3_conv1_Branch_3_1_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_1_conv (Con (None, 56, 56, 96)   24576       block3_conv1_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_2_conv (Con (None, 56, 56, 16)   4096        block3_conv1_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_1_bn (Batch (None, 56, 56, 96)   288         block3_conv2_Branch_1_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_2_bn (Batch (None, 56, 56, 16)   48          block3_conv2_Branch_2_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_1_act (Acti (None, 56, 56, 96)   0           block3_conv2_Branch_1_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_2_act (Acti (None, 56, 56, 16)   0           block3_conv2_Branch_2_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_3 (MaxPooli (None, 56, 56, 256)  0           block3_conv1_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_0_conv (Con (None, 56, 56, 64)   16384       block3_conv1_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_1_1_conv (C (None, 56, 56, 128)  110592      block3_conv2_Branch_1_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_2_1_conv (C (None, 56, 56, 32)   12800       block3_conv2_Branch_2_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_3_1_conv (C (None, 56, 56, 32)   8192        block3_conv2_Branch_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_0_bn (Batch (None, 56, 56, 64)   192         block3_conv2_Branch_0_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_1_1_bn (Bat (None, 56, 56, 128)  384         block3_conv2_Branch_1_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_2_1_bn (Bat (None, 56, 56, 32)   96          block3_conv2_Branch_2_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_3_1_bn (Bat (None, 56, 56, 32)   96          block3_conv2_Branch_3_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_0_act (Acti (None, 56, 56, 64)   0           block3_conv2_Branch_0_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_1_1_act (Ac (None, 56, 56, 128)  0           block3_conv2_Branch_1_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_2_1_act (Ac (None, 56, 56, 32)   0           block3_conv2_Branch_2_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Branch_3_1_act (Ac (None, 56, 56, 32)   0           block3_conv2_Branch_3_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_Concatenated (Conc (None, 56, 56, 256)  0           block3_conv2_Branch_0_act[0][0]  \n",
      "                                                                 block3_conv2_Branch_1_1_act[0][0]\n",
      "                                                                 block3_conv2_Branch_2_1_act[0][0]\n",
      "                                                                 block3_conv2_Branch_3_1_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_1_conv (Con (None, 56, 56, 96)   24576       block3_conv2_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_2_conv (Con (None, 56, 56, 16)   4096        block3_conv2_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_1_bn (Batch (None, 56, 56, 96)   288         block3_conv3_Branch_1_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_2_bn (Batch (None, 56, 56, 16)   48          block3_conv3_Branch_2_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_1_act (Acti (None, 56, 56, 96)   0           block3_conv3_Branch_1_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_2_act (Acti (None, 56, 56, 16)   0           block3_conv3_Branch_2_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_3 (MaxPooli (None, 56, 56, 256)  0           block3_conv2_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_0_conv (Con (None, 56, 56, 64)   16384       block3_conv2_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_1_1_conv (C (None, 56, 56, 128)  110592      block3_conv3_Branch_1_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_2_1_conv (C (None, 56, 56, 32)   12800       block3_conv3_Branch_2_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_3_1_conv (C (None, 56, 56, 32)   8192        block3_conv3_Branch_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_0_bn (Batch (None, 56, 56, 64)   192         block3_conv3_Branch_0_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_1_1_bn (Bat (None, 56, 56, 128)  384         block3_conv3_Branch_1_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_2_1_bn (Bat (None, 56, 56, 32)   96          block3_conv3_Branch_2_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_3_1_bn (Bat (None, 56, 56, 32)   96          block3_conv3_Branch_3_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_0_act (Acti (None, 56, 56, 64)   0           block3_conv3_Branch_0_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_1_1_act (Ac (None, 56, 56, 128)  0           block3_conv3_Branch_1_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_2_1_act (Ac (None, 56, 56, 32)   0           block3_conv3_Branch_2_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Branch_3_1_act (Ac (None, 56, 56, 32)   0           block3_conv3_Branch_3_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_Concatenated (Conc (None, 56, 56, 256)  0           block3_conv3_Branch_0_act[0][0]  \n",
      "                                                                 block3_conv3_Branch_1_1_act[0][0]\n",
      "                                                                 block3_conv3_Branch_2_1_act[0][0]\n",
      "                                                                 block3_conv3_Branch_3_1_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_conv (Conv2D)      (None, 28, 28, 512)  1179648     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_bn (BatchNormaliza (None, 28, 28, 512)  1536        block4_conv1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_act (Activation)   (None, 28, 28, 512)  0           block4_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_conv (Conv2D)      (None, 28, 28, 512)  2359296     block4_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_bn (BatchNormaliza (None, 28, 28, 512)  1536        block4_conv2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_act (Activation)   (None, 28, 28, 512)  0           block4_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_conv (Conv2D)      (None, 28, 28, 512)  2359296     block4_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_bn (BatchNormaliza (None, 28, 28, 512)  1536        block4_conv3_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_act (Activation)   (None, 28, 28, 512)  0           block4_conv3_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_conv (Con (None, 14, 14, 192)  98304       block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_bn (Batch (None, 14, 14, 192)  576         block5_conv1_Branch_1_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_act (Acti (None, 14, 14, 192)  0           block5_conv1_Branch_1_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_1_conv (C (None, 14, 14, 256)  147456      block5_conv1_Branch_1_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_1_bn (Bat (None, 14, 14, 256)  768         block5_conv1_Branch_1_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_1_act (Ac (None, 14, 14, 256)  0           block5_conv1_Branch_1_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_2_conv (C (None, 14, 14, 256)  196608      block5_conv1_Branch_1_1_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_2_bn (Bat (None, 14, 14, 256)  768         block5_conv1_Branch_1_2_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_1_2_act (Ac (None, 14, 14, 256)  0           block5_conv1_Branch_1_2_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_pool (MaxPooling2D (None, 14, 14, 512)  0           block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_0_conv (Con (None, 14, 14, 128)  65536       block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_2_2_conv (C (None, 14, 14, 256)  327680      block5_conv1_Branch_1_2_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_3_conv (Con (None, 14, 14, 64)   32768       block5_conv1_pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_0_bn (Batch (None, 14, 14, 128)  384         block5_conv1_Branch_0_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_2_2_bn (Bat (None, 14, 14, 256)  768         block5_conv1_Branch_2_2_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_3_bn (Batch (None, 14, 14, 64)   192         block5_conv1_Branch_3_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_0_act (Acti (None, 14, 14, 128)  0           block5_conv1_Branch_0_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_2_2_act (Ac (None, 14, 14, 256)  0           block5_conv1_Branch_2_2_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Branch_3_act (Acti (None, 14, 14, 64)   0           block5_conv1_Branch_3_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_Concatenated (Conc (None, 14, 14, 704)  0           block5_conv1_Branch_0_act[0][0]  \n",
      "                                                                 block5_conv1_Branch_1_2_act[0][0]\n",
      "                                                                 block5_conv1_Branch_2_2_act[0][0]\n",
      "                                                                 block5_conv1_Branch_3_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_conv (Con (None, 14, 14, 192)  135168      block5_conv1_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_bn (Batch (None, 14, 14, 192)  576         block5_conv2_Branch_1_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_act (Acti (None, 14, 14, 192)  0           block5_conv2_Branch_1_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_1_conv (C (None, 14, 14, 256)  147456      block5_conv2_Branch_1_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_1_bn (Bat (None, 14, 14, 256)  768         block5_conv2_Branch_1_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_1_act (Ac (None, 14, 14, 256)  0           block5_conv2_Branch_1_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_2_conv (C (None, 14, 14, 256)  196608      block5_conv2_Branch_1_1_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_2_bn (Bat (None, 14, 14, 256)  768         block5_conv2_Branch_1_2_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_1_2_act (Ac (None, 14, 14, 256)  0           block5_conv2_Branch_1_2_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_pool (MaxPooling2D (None, 14, 14, 704)  0           block5_conv1_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_0_conv (Con (None, 14, 14, 128)  90112       block5_conv1_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_2_2_conv (C (None, 14, 14, 256)  327680      block5_conv2_Branch_1_2_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_3_conv (Con (None, 14, 14, 64)   45056       block5_conv2_pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_0_bn (Batch (None, 14, 14, 128)  384         block5_conv2_Branch_0_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_2_2_bn (Bat (None, 14, 14, 256)  768         block5_conv2_Branch_2_2_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_3_bn (Batch (None, 14, 14, 64)   192         block5_conv2_Branch_3_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_0_act (Acti (None, 14, 14, 128)  0           block5_conv2_Branch_0_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_2_2_act (Ac (None, 14, 14, 256)  0           block5_conv2_Branch_2_2_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Branch_3_act (Acti (None, 14, 14, 64)   0           block5_conv2_Branch_3_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_Concatenated (Conc (None, 14, 14, 704)  0           block5_conv2_Branch_0_act[0][0]  \n",
      "                                                                 block5_conv2_Branch_1_2_act[0][0]\n",
      "                                                                 block5_conv2_Branch_2_2_act[0][0]\n",
      "                                                                 block5_conv2_Branch_3_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_conv (Con (None, 14, 14, 192)  135168      block5_conv2_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_bn (Batch (None, 14, 14, 192)  576         block5_conv3_Branch_1_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_act (Acti (None, 14, 14, 192)  0           block5_conv3_Branch_1_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_1_conv (C (None, 14, 14, 256)  147456      block5_conv3_Branch_1_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_1_bn (Bat (None, 14, 14, 256)  768         block5_conv3_Branch_1_1_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_1_act (Ac (None, 14, 14, 256)  0           block5_conv3_Branch_1_1_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_2_conv (C (None, 14, 14, 256)  196608      block5_conv3_Branch_1_1_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_2_bn (Bat (None, 14, 14, 256)  768         block5_conv3_Branch_1_2_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_1_2_act (Ac (None, 14, 14, 256)  0           block5_conv3_Branch_1_2_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_pool (MaxPooling2D (None, 14, 14, 704)  0           block5_conv2_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_0_conv (Con (None, 14, 14, 128)  90112       block5_conv2_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_2_2_conv (C (None, 14, 14, 256)  327680      block5_conv3_Branch_1_2_act[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_3_conv (Con (None, 14, 14, 64)   45056       block5_conv3_pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_0_bn (Batch (None, 14, 14, 128)  384         block5_conv3_Branch_0_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_2_2_bn (Bat (None, 14, 14, 256)  768         block5_conv3_Branch_2_2_conv[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_3_bn (Batch (None, 14, 14, 64)   192         block5_conv3_Branch_3_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_0_act (Acti (None, 14, 14, 128)  0           block5_conv3_Branch_0_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_2_2_act (Ac (None, 14, 14, 256)  0           block5_conv3_Branch_2_2_bn[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Branch_3_act (Acti (None, 14, 14, 64)   0           block5_conv3_Branch_3_bn[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_Concatenated (Conc (None, 14, 14, 704)  0           block5_conv3_Branch_0_act[0][0]  \n",
      "                                                                 block5_conv3_Branch_1_2_act[0][0]\n",
      "                                                                 block5_conv3_Branch_2_2_act[0][0]\n",
      "                                                                 block5_conv3_Branch_3_act[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 704)    0           block5_conv3_Concatenated[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 704)          0           block5_pool[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 9,432,112\n",
      "Trainable params: 9,419,152\n",
      "Non-trainable params: 12,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
